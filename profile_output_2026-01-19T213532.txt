Timer unit: 1e-09 s
Commit: a27801252411 (19/01/2026)

Total time: 33780.3 s
File: /cfs/home/u036846/knn-vc/hifigan/train.py
Function: train at line 49

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    49                                           @profile
    50                                           def train(rank, a, h):
    51         1       2040.0   2040.0      0.0      if h.num_gpus > 1:
    52                                                   init_process_group(
    53                                                       backend=h.dist_config["dist_backend"],
    54                                                       init_method=h.dist_config["dist_url"],
    55                                                       world_size=h.dist_config["world_size"] * h.num_gpus,
    56                                                       rank=rank,
    57                                                   )
    58                                           
    59         1      31250.0  31250.0      0.0      if torch.cuda.is_available():
    60         1  140497057.0  1.4e+08      0.0          torch.cuda.manual_seed(h.seed)
    61         1       1710.0   1710.0      0.0          device = "cuda:{:d}".format(rank)
    62                                               else:
    63                                                   device = "cpu"
    64                                               
    65         1     171058.0 171058.0      0.0      LOGGER.info(f"Device: {device}")
    66         1  258616447.0 2.59e+08      0.0      generator = Generator(h).to(device)
    67         1  171632497.0 1.72e+08      0.0      mpd = MultiPeriodDiscriminator().to(device)
    68         1  121514201.0 1.22e+08      0.0      msd = MultiScaleDiscriminator().to(device)
    69                                           
    70         1        920.0    920.0      0.0      if rank == 0:
    71         1      77409.0  77409.0      0.0          os.makedirs(a.checkpoint_path, exist_ok=True)
    72         1     747683.0 747683.0      0.0          LOGGER.info("checkpoints directory : ", a.checkpoint_path)
    73                                           
    74         1       2660.0   2660.0      0.0      if os.path.isdir(a.checkpoint_path):
    75         1    2744867.0 2.74e+06      0.0          cp_g = scan_checkpoint(a.checkpoint_path, "g_")
    76         1     144758.0 144758.0      0.0          cp_do = scan_checkpoint(a.checkpoint_path, "do_")
    77                                           
    78         1        160.0    160.0      0.0      steps = 0
    79         1        160.0    160.0      0.0      if cp_g is None or cp_do is None:
    80         1         90.0     90.0      0.0          state_dict_do = None
    81         1        260.0    260.0      0.0          last_epoch = -1
    82                                               else:
    83                                                   state_dict_g = load_checkpoint(cp_g, device)
    84                                                   state_dict_do = load_checkpoint(cp_do, device)
    85                                                   generator.load_state_dict(state_dict_g["generator"])
    86                                                   mpd.load_state_dict(state_dict_do["mpd"])
    87                                                   msd.load_state_dict(state_dict_do["msd"])
    88                                                   steps = state_dict_do["steps"] + 1
    89                                                   last_epoch = state_dict_do["epoch"]
    90                                                   LOGGER.info(f"Restored checkpoint from {cp_g} and {cp_do}")
    91                                           
    92         1       1750.0   1750.0      0.0      if h.num_gpus > 1:
    93                                                   LOGGER.info("Multi-gpu detected")
    94                                                   generator = DistributedDataParallel(generator, device_ids=[rank]).to(device)
    95                                                   mpd = DistributedDataParallel(mpd, device_ids=[rank]).to(device)
    96                                                   msd = DistributedDataParallel(msd, device_ids=[rank]).to(device)
    97                                           
    98         2    1180590.0 590295.0      0.0      optim_g = torch.optim.AdamW(
    99         1       3570.0   3570.0      0.0          generator.parameters(), h.learning_rate, betas=[h.adam_b1, h.adam_b2]
   100                                               )
   101         2     663124.0 331562.0      0.0      optim_d = torch.optim.AdamW(
   102         1       2460.0   2460.0      0.0          itertools.chain(msd.parameters(), mpd.parameters()),
   103         1        240.0    240.0      0.0          h.learning_rate,
   104         1        240.0    240.0      0.0          betas=[h.adam_b1, h.adam_b2],
   105                                               )
   106                                           
   107         1        260.0    260.0      0.0      if state_dict_do is not None:
   108                                                   optim_g.load_state_dict(state_dict_do["optim_g"])
   109                                                   optim_d.load_state_dict(state_dict_do["optim_d"])
   110                                           
   111         2      55350.0  27675.0      0.0      scheduler_g = torch.optim.lr_scheduler.ExponentialLR(
   112         1        500.0    500.0      0.0          optim_g, gamma=h.lr_decay, last_epoch=last_epoch
   113                                               )
   114         2      18630.0   9315.0      0.0      scheduler_d = torch.optim.lr_scheduler.ExponentialLR(
   115         1        210.0    210.0      0.0          optim_d, gamma=h.lr_decay, last_epoch=last_epoch
   116                                               )
   117         1        430.0    430.0      0.0      if a.fp16:
   118                                                   scaler_g = GradScaler()
   119                                                   scaler_d = GradScaler()
   120                                           
   121         1   23234449.0 2.32e+07      0.0      train_df, valid_df = get_dataset_filelist(a)
   122                                           
   123         2    2647907.0 1.32e+06      0.0      trainset = SslDataset(
   124         1        140.0    140.0      0.0          train_df,
   125         1        910.0    910.0      0.0          h.segment_size,
   126         1        300.0    300.0      0.0          h.n_fft,
   127         1        340.0    340.0      0.0          h.num_mels,
   128         1        370.0    370.0      0.0          h.hop_size,
   129         1        310.0    310.0      0.0          h.win_size,
   130         1        340.0    340.0      0.0          h.sampling_rate,
   131         1        440.0    440.0      0.0          h.fmin,
   132         1        190.0    190.0      0.0          h.fmax,
   133         1        200.0    200.0      0.0          n_cache_reuse=0,
   134         1        440.0    440.0      0.0          shuffle=False if h.num_gpus > 1 else True,
   135         1        150.0    150.0      0.0          fmax_loss=h.fmax_for_loss,
   136         1        210.0    210.0      0.0          device=device,
   137         1        320.0    320.0      0.0          audio_root_path=a.audio_root_path,
   138         1        350.0    350.0      0.0          feat_root_path=a.feature_root_path,
   139                                               )
   140                                           
   141         1        570.0    570.0      0.0      train_sampler = DistributedSampler(trainset) if h.num_gpus > 1 else None
   142                                           
   143         2     200668.0 100334.0      0.0      train_loader = DataLoader(
   144         1        130.0    130.0      0.0          trainset,
   145         1        290.0    290.0      0.0          num_workers=h.num_workers,
   146         1        130.0    130.0      0.0          shuffle=False,
   147         1        120.0    120.0      0.0          sampler=train_sampler,
   148         1        480.0    480.0      0.0          batch_size=h.batch_size,
   149         1        130.0    130.0      0.0          pin_memory=True,
   150         1        120.0    120.0      0.0          persistent_workers=True,
   151         1        120.0    120.0      0.0          drop_last=True,
   152                                               )
   153                                           
   154         3     556316.0 185438.7      0.0      melspec = LogMelSpectrogram(
   155         1        790.0    790.0      0.0          h.n_fft, h.num_mels, h.sampling_rate, h.hop_size, h.win_size, h.fmin, h.fmax
   156         1     124119.0 124119.0      0.0      ).to(device)
   157                                           
   158         1        290.0    290.0      0.0      if rank == 0:
   159         2     468066.0 234033.0      0.0          validset = SslDataset(
   160         1        140.0    140.0      0.0              valid_df,
   161         1        340.0    340.0      0.0              h.segment_size,
   162         1        160.0    160.0      0.0              h.n_fft,
   163         1        170.0    170.0      0.0              h.num_mels,
   164         1        250.0    250.0      0.0              h.hop_size,
   165         1        150.0    150.0      0.0              h.win_size,
   166         1        130.0    130.0      0.0              h.sampling_rate,
   167         1        140.0    140.0      0.0              h.fmin,
   168         1        130.0    130.0      0.0              h.fmax,
   169         1        130.0    130.0      0.0              False,
   170         1        110.0    110.0      0.0              False,
   171         1        110.0    110.0      0.0              n_cache_reuse=0,
   172         1        130.0    130.0      0.0              fmax_loss=h.fmax_for_loss,
   173         1        120.0    120.0      0.0              device=device,
   174         1        300.0    300.0      0.0              audio_root_path=a.audio_root_path,
   175         1        210.0    210.0      0.0              feat_root_path=a.feature_root_path,
   176                                                   )
   177         2      38730.0  19365.0      0.0          validation_loader = DataLoader(
   178         1        160.0    160.0      0.0              validset,
   179         1        170.0    170.0      0.0              num_workers=1,
   180         1        120.0    120.0      0.0              shuffle=False,
   181         1        120.0    120.0      0.0              sampler=None,
   182         1        130.0    130.0      0.0              batch_size=1,
   183         1        110.0    110.0      0.0              pin_memory=True,
   184         1        110.0    110.0      0.0              persistent_workers=True,
   185         1        110.0    110.0      0.0              drop_last=True,
   186                                                   )
   187                                           
   188         1    6591873.0 6.59e+06      0.0          sw = SummaryWriter(os.path.join(a.checkpoint_path, "logs"))
   189                                           
   190         1     633795.0 633795.0      0.0      generator.train()
   191         1     216938.0 216938.0      0.0      mpd.train()
   192         1     170718.0 170718.0      0.0      msd.train()
   193                                           
   194         1        370.0    370.0      0.0      if rank == 0:
   195         1    1172210.0 1.17e+06      0.0          mb = tqdm(range(max(0, last_epoch), a.training_epochs))
   196                                               else:
   197                                                   mb = range(max(0, last_epoch), a.training_epochs)
   198                                           
   199       136   28485305.0 209450.8      0.0      for epoch in mb:
   200       136      32419.0    238.4      0.0          if rank == 0:
   201       136      59269.0    435.8      0.0              start = time.time()
   202       136   23160704.0 170299.3      0.0              mb.write("Epoch: {}".format(epoch + 1))
   203                                           
   204       136     400898.0   2947.8      0.0          if h.num_gpus > 1:
   205                                                       train_sampler.set_epoch(epoch)
   206                                           
   207    120537     3.71e+10 307464.1      0.1          for i, batch in enumerate(train_loader):
   208    120402   37929846.0    315.0      0.0              if rank == 0:
   209    120402  127043411.0   1055.2      0.0                  start_b = time.time()
   210    120402 4532837554.0  37647.5      0.0              x, y, _, y_mel = batch
   211    120402 2612644436.0  21699.3      0.0              x = x.to(device, non_blocking=True)
   212    120402  760973278.0   6320.3      0.0              y = y.to(device, non_blocking=True)
   213    120402  634378924.0   5268.8      0.0              y_mel = y_mel.to(device, non_blocking=True)
   214    120402  606814770.0   5039.9      0.0              y = y.unsqueeze(1)
   215                                           
   216    240804 2506191109.0  10407.6      0.0              with torch.amp.autocast(enabled=a.fp16, device_type=device):
   217    120402     1.49e+12 1.23e+07      4.4                  y_g_hat = generator(x)
   218    120402     2.62e+10 217733.1      0.1                  y_g_hat_mel = melspec(y_g_hat.squeeze(1))
   219                                           
   220    120402     3.11e+10 258396.2      0.1              optim_d.zero_grad()
   221                                           
   222    240804 2324783558.0   9654.3      0.0              with torch.amp.autocast(enabled=a.fp16, device_type=device):
   223                                                           # MPD
   224    120402     8.03e+11 6.67e+06      2.4                  y_df_hat_r, y_df_hat_g, _, _ = mpd(y, y_g_hat.detach())
   225    240804        2e+12 8.29e+06      5.9                  loss_disc_f, losses_disc_f_r, losses_disc_f_g = discriminator_loss(
   226    120402   17323232.0    143.9      0.0                      y_df_hat_r, y_df_hat_g
   227                                                           )
   228                                           
   229                                                           # MSD
   230    120402     8.07e+11  6.7e+06      2.4                  y_ds_hat_r, y_ds_hat_g, _, _ = msd(y, y_g_hat.detach())
   231    240804     1.23e+12  5.1e+06      3.6                  loss_disc_s, losses_disc_s_r, losses_disc_s_g = discriminator_loss(
   232    120402   16385330.0    136.1      0.0                      y_ds_hat_r, y_ds_hat_g
   233                                                           )
   234                                           
   235    120402     2.22e+10 184024.5      0.1                  loss_disc_all = loss_disc_s + loss_disc_f
   236                                           
   237    120402   56549537.0    469.7      0.0              if a.fp16:
   238                                                           scaler_d.scale(loss_disc_all).backward()
   239                                                           scaler_d.step(optim_d)
   240                                                           scaler_d.update()
   241                                                       else:
   242    120402     2.61e+12 2.17e+07      7.7                  loss_disc_all.backward()
   243    120402      4.3e+11 3.57e+06      1.3                  optim_d.step()
   244                                           
   245                                                       # Generator
   246    120402     3.88e+10 322130.2      0.1              optim_g.zero_grad()
   247                                           
   248    240804 2621300466.0  10885.6      0.0              with torch.amp.autocast(enabled=a.fp16, device_type=device):
   249                                                           # L1 Mel-Spectrogram Loss
   250    120402     5.07e+10 421140.2      0.2                  loss_mel = F.l1_loss(y_mel, y_g_hat_mel) * 45
   251                                           
   252    120402     1.49e+12 1.24e+07      4.4                  y_df_hat_r, y_df_hat_g, fmap_f_r, fmap_f_g = mpd(y, y_g_hat)
   253    120402     1.69e+12  1.4e+07      5.0                  y_ds_hat_r, y_ds_hat_g, fmap_s_r, fmap_s_g = msd(y, y_g_hat)
   254    120402     3.22e+11 2.67e+06      1.0                  loss_fm_f = feature_loss(fmap_f_r, fmap_f_g)
   255    120402     2.21e+11 1.84e+06      0.7                  loss_fm_s = feature_loss(fmap_s_r, fmap_s_g)
   256    120402     4.64e+10 385558.5      0.1                  loss_gen_f, losses_gen_f = generator_loss(y_df_hat_g)
   257    120402     2.44e+10 203059.2      0.1                  loss_gen_s, losses_gen_s = generator_loss(y_ds_hat_g)
   258    120402     3.91e+10 324683.1      0.1                  loss_gen_all = (
   259    120402 9121988847.0  75762.8      0.0                      loss_gen_s + loss_gen_f + loss_fm_s + loss_fm_f + loss_mel
   260                                                           )
   261                                           
   262    120402   49637023.0    412.3      0.0              if a.fp16:
   263                                                           scaler_g.scale(loss_gen_all).backward()
   264                                                           scaler_g.step(optim_g)
   265                                                           scaler_g.update()
   266                                                       else:
   267    120402     9.51e+12  7.9e+07     28.2                  loss_gen_all.backward()
   268    120401     3.33e+11 2.77e+06      1.0                  optim_g.step()
   269                                           
   270    120401   41074101.0    341.1      0.0              if rank == 0:
   271                                                           # STDOUT logging
   272    120401   83284972.0    691.7      0.0                  if steps % a.stdout_interval == 0:
   273      2410    7855601.0   3259.6      0.0                      with torch.no_grad():
   274      1205     2.37e+10 1.97e+07      0.1                          mel_error = F.l1_loss(y_mel, y_g_hat_mel).item()
   275                                           
   276      2410  342983603.0 142316.8      0.0                      mb.write(
   277      2410   39359740.0  16331.8      0.0                          "Steps : {:,d}, Gen Loss Total : {:4.3f}, Mel-Spec. Error : {:4.3f}, sec/batch : {:4.3f}, peak mem: {:5.2f}GB".format(
   278      1205     167419.0    138.9      0.0                              steps,
   279      1205     124889.0    103.6      0.0                              loss_gen_all,
   280      1205     111349.0     92.4      0.0                              mel_error,
   281      1205    1538742.0   1277.0      0.0                              time.time() - start_b,
   282      1205  295280260.0 245045.9      0.0                              torch.cuda.max_memory_allocated() / 1e9,
   283                                                                   )
   284                                                               )
   285                                           
   286                                                           # checkpointing
   287    120401   62813291.0    521.7      0.0                  if steps % a.checkpoint_interval == 0 and steps != 0:
   288        24      45250.0   1885.4      0.0                      checkpoint_path = "{}/g_{:08d}.pt".format(a.checkpoint_path, steps)
   289        48      3.6e+10 7.49e+08      0.1                      save_checkpoint(
   290        24       3470.0    144.6      0.0                          checkpoint_path,
   291        24      11960.0    498.3      0.0                          {
   292        24       4850.0    202.1      0.0                              "generator": (
   293        24      60510.0   2521.2      0.0                                  generator.module if h.num_gpus > 1 else generator
   294        24   16768017.0 698667.4      0.0                              ).state_dict()
   295                                                                   },
   296                                                               )
   297        24     168400.0   7016.7      0.0                      checkpoint_path = "{}/do_{:08d}.pt".format(a.checkpoint_path, steps)
   298        48     4.48e+10 9.34e+08      0.1                      save_checkpoint(
   299        24       5720.0    238.3      0.0                          checkpoint_path,
   300        24      29560.0   1231.7      0.0                          {
   301        24    8821145.0 367547.7      0.0                              "mpd": (mpd.module if h.num_gpus > 1 else mpd).state_dict(),
   302        24    6641479.0 276728.3      0.0                              "msd": (msd.module if h.num_gpus > 1 else msd).state_dict(),
   303        24    7156059.0 298169.1      0.0                              "optim_g": optim_g.state_dict(),
   304        24    3785667.0 157736.1      0.0                              "optim_d": optim_d.state_dict(),
   305        24       3580.0    149.2      0.0                              "steps": steps,
   306        24       3340.0    139.2      0.0                              "epoch": epoch,
   307                                                                   },
   308                                                               )
   309                                           
   310                                                           # Tensorboard summary logging
   311    120401   52964207.0    439.9      0.0                  if steps % a.summary_interval == 0:
   312      4817     7.16e+10 1.49e+07      0.2                      sw.add_scalar("training/gen_loss_total", loss_gen_all, steps)
   313      4817  137179818.0  28478.3      0.0                      sw.add_scalar("training/mel_spec_error", mel_error, steps)
   314      4817  511334974.0 106152.2      0.0                      sw.add_scalar("training/disc_loss_total", loss_disc_all, steps)
   315                                           
   316                                                           # Validation
   317    120401   41557594.0    345.2      0.0                  if steps % a.validation_interval == 0:  # and steps != 0:
   318        25   16819824.0 672793.0      0.0                      generator.eval()
   319        25  225123285.0    9e+06      0.0                      torch.cuda.empty_cache()
   320        25      13460.0    538.4      0.0                      val_err_tot = 0
   321        50     953609.0  19072.2      0.0                      with torch.no_grad():
   322     67600     1.04e+10 154436.2      0.0                          for j, batch in enumerate(validation_loader):
   323     67575  936371872.0  13856.8      0.0                              x, y, _, y_mel = batch
   324     67575     1.02e+13 1.51e+08     30.3                              y_g_hat = generator(x.to(device))
   325     67575 1481221348.0  21919.7      0.0                              y_mel = y_mel.to(device, non_blocking=True)
   326     67575     2.94e+10 434647.4      0.1                              y_g_hat_mel = melspec(y_g_hat.squeeze(1))
   327     67575   61124435.0    904.5      0.0                              if y_g_hat_mel.shape[-1] != y_mel.shape[-1]:
   328                                                                           # pad it
   329                                                                           n_pad = h.hop_size
   330                                                                           y_g_hat = F.pad(
   331                                                                               y_g_hat, (n_pad // 2, n_pad - n_pad // 2)
   332                                                                           )
   333                                                                           y_g_hat_mel = melspec(y_g_hat.squeeze(1))
   334                                           
   335     67575     6.05e+10 895905.9      0.2                              val_err_tot += F.l1_loss(y_mel, y_g_hat_mel).item()
   336                                           
   337     67575   32967025.0    487.9      0.0                              if j <= 4:
   338       125      29430.0    235.4      0.0                                  if steps == 0:
   339        10    3969096.0 396909.6      0.0                                      sw.add_audio(
   340         5       6590.0   1318.0      0.0                                          "gt/y_{}".format(j),
   341         5      30460.0   6092.0      0.0                                          y[0],
   342         5        550.0    110.0      0.0                                          steps,
   343         5       4260.0    852.0      0.0                                          h.sampling_rate,
   344                                                                               )
   345                                           
   346       250  138330954.0 553323.8      0.0                                  sw.add_audio(
   347       125     197148.0   1577.2      0.0                                      "generated/y_hat_{}".format(j),
   348       125     669425.0   5355.4      0.0                                      y_g_hat[0],
   349       125      16249.0    130.0      0.0                                      steps,
   350       125      92680.0    741.4      0.0                                      h.sampling_rate,
   351                                                                           )
   352                                           
   353        25      39199.0   1568.0      0.0                          val_err = val_err_tot / (j + 1)
   354        25    3975206.0 159008.2      0.0                          sw.add_scalar("validation/mel_spec_error", val_err, steps)
   355        50   11309683.0 226193.7      0.0                          mb.write(
   356        25     239327.0   9573.1      0.0                              f"validation run complete at {steps:,d} steps. validation mel spec error: {val_err:5.4f}"
   357                                                                   )
   358                                           
   359        25   13970804.0 558832.2      0.0                      generator.train()
   360        50    2099129.0  41982.6      0.0                      sw.add_scalar(
   361        25       3579.0    143.2      0.0                          "memory/max_allocated_gb",
   362        25    6740003.0 269600.1      0.0                          torch.cuda.max_memory_allocated() / 1e9,
   363        25       4410.0    176.4      0.0                          steps,
   364                                                               )
   365        50     368538.0   7370.8      0.0                      sw.add_scalar(
   366        25       2900.0    116.0      0.0                          "memory/max_reserved_gb",
   367        25    4152438.0 166097.5      0.0                          torch.cuda.max_memory_reserved() / 1e9,
   368        25       3600.0    144.0      0.0                          steps,
   369                                                               )
   370        25       8400.0    336.0      0.0                      if "cuda" in device:
   371        25     326248.0  13049.9      0.0                          torch.cuda.reset_peak_memory_stats()
   372        25     250766.0  10030.6      0.0                          torch.cuda.reset_accumulated_memory_stats()
   373                                           
   374    120401   54531965.0    452.9      0.0              steps += 1
   375                                           
   376       135    3324687.0  24627.3      0.0          scheduler_g.step()
   377       135     749735.0   5553.6      0.0          scheduler_d.step()
   378                                           
   379       135      28929.0    214.3      0.0          if rank == 0:
   380       270 4959290335.0 1.84e+07      0.0              LOGGER.info(
   381       270     641063.0   2374.3      0.0                  "Time taken for epoch {} is {} sec".format(
   382       135     184239.0   1364.7      0.0                      epoch + 1, int(time.time() - start)
   383                                                           )
   384                                                       )

33780.34 seconds - /cfs/home/u036846/knn-vc/hifigan/train.py:49 - train
